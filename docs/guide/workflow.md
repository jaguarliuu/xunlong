# Workflow

Understanding XunLong's workflow helps you optimize your content generation process and troubleshoot issues effectively.

## High-Level Workflow

```mermaid
graph LR
    A[ğŸ‘¤ User Input] --> B[ğŸ” Requirement Analysis]
    B --> C[ğŸ“‹ Task Decomposition]
    C --> D[ğŸŒ Parallel Search]
    D --> E[ğŸ“¦ Content Integration]
    E --> F[âœ¨ Intelligent Generation]
    F --> G[âœ… Quality Review]
    G --> H[ğŸ”„ Format Conversion]
    H --> I[ğŸ“¤ Export Output]

    style A fill:#e3f2fd,stroke:#1976d2
    style B fill:#f3e5f5,stroke:#7b1fa2
    style C fill:#f3e5f5,stroke:#7b1fa2
    style D fill:#fff3e0,stroke:#f57c00
    style E fill:#fff3e0,stroke:#f57c00
    style F fill:#e8f5e9,stroke:#388e3c
    style G fill:#e8f5e9,stroke:#388e3c
    style H fill:#fce4ec,stroke:#c2185b
    style I fill:#fce4ec,stroke:#c2185b
```

## Detailed Workflow Stages

### Stage 1: Requirement Analysis ğŸ”

**Goal:** Understand user intent and prepare for execution.

**Activities:**
1. Parse command-line arguments
2. Identify content type (report/fiction/ppt)
3. Extract parameters (style, depth, chapters, etc.)
4. Validate configuration
5. Initialize project structure

**Output:**
```python
{
    "content_type": "report",
    "query": "AI Industry Trends 2025",
    "style": "business",
    "depth": "comprehensive",
    "project_id": "20251005_143022"
}
```

**Duration:** ~1 second

### Stage 2: Task Decomposition ğŸ“‹

**Goal:** Break down complex request into manageable subtasks.

**Process:**
```mermaid
graph TD
    A[User Query] --> B{Content Type?}
    B -->|Report| C[Decompose Report Tasks]
    B -->|Fiction| D[Decompose Fiction Tasks]
    B -->|PPT| E[Decompose PPT Tasks]
    
    C --> C1[Identify Topics]
    C --> C2[Plan Sections]
    C --> C3[Define Search Queries]
    
    D --> D1[Plot Structure]
    D --> D2[Character Design]
    D --> D3[Chapter Outline]
    
    E --> E1[Slide Structure]
    E --> E2[Visual Design]
    E --> E3[Content Allocation]
```

**Example Decomposition:**

::: tabs

== Report
```json
{
  "tasks": [
    {
      "type": "search",
      "queries": [
        "AI industry market size 2025",
        "Latest AI technology trends",
        "AI applications by sector"
      ]
    },
    {
      "type": "outline",
      "sections": [
        "Executive Summary",
        "Market Overview",
        "Technology Trends",
        "Applications",
        "Future Outlook"
      ]
    }
  ]
}
```

== Fiction
```json
{
  "tasks": [
    {
      "type": "plot",
      "structure": "three_act"
    },
    {
      "type": "characters",
      "count": 5,
      "depth": "detailed"
    },
    {
      "type": "chapters",
      "count": 12,
      "style": "mystery"
    }
  ]
}
```

== PPT
```json
{
  "tasks": [
    {
      "type": "outline",
      "slides": 15
    },
    {
      "type": "design",
      "style": "business",
      "colors": "professional"
    },
    {
      "type": "content",
      "distribution": "balanced"
    }
  ]
}
```

:::

**Duration:** ~2-3 seconds

### Stage 3: Parallel Search ğŸŒ

**Goal:** Gather relevant information from the web.

**Execution Flow:**
```mermaid
sequenceDiagram
    participant C as Coordinator
    participant S1 as Search Task 1
    participant S2 as Search Task 2
    participant S3 as Search Task 3
    participant A as Aggregator

    C->>S1: Execute search
    C->>S2: Execute search
    C->>S3: Execute search
    
    par Parallel Execution
        S1->>S1: Search & Extract
        S2->>S2: Search & Extract
        S3->>S3: Search & Extract
    end
    
    S1->>A: Results
    S2->>A: Results
    S3->>A: Results
    A->>C: Aggregated Results
```

**Search Process:**
1. **Execute Query** - Use Perplexity or Playwright
2. **Extract Content** - Parse HTML and extract text
3. **Filter Results** - Remove irrelevant content
4. **Summarize** - Create concise summaries
5. **Cite Sources** - Track URLs and dates

**Duration:** ~5-15 seconds (depends on query count)

### Stage 4: Content Integration ğŸ“¦

**Goal:** Organize and structure collected information.

**Activities:**
1. Deduplicate information
2. Categorize by topic
3. Rank by relevance
4. Create knowledge graph
5. Prepare context for generation

**Data Structure:**
```python
{
    "topic": "AI Industry Trends",
    "sources": [
        {
            "url": "https://...",
            "date": "2025-09-15",
            "relevance": 0.95,
            "summary": "...",
            "key_points": [...]
        }
    ],
    "knowledge_graph": {
        "entities": [...],
        "relationships": [...]
    }
}
```

**Duration:** ~2-3 seconds

### Stage 5: Intelligent Generation âœ¨

**Goal:** Create high-quality content based on gathered materials.

**Generation Strategy:**

```mermaid
graph TD
    A[Start Generation] --> B{Content Type}
    
    B -->|Report| C[Generate Outline]
    C --> D[Generate Sections]
    D --> E[Add Citations]
    E --> F[Create Tables/Charts]
    
    B -->|Fiction| G[Develop Plot]
    G --> H[Create Characters]
    H --> I[Write Chapters]
    I --> J[Ensure Consistency]
    
    B -->|PPT| K[Design Layout]
    K --> L[Allocate Content]
    L --> M[Add Visuals]
    M --> N[Generate Notes]
    
    F --> O[Combine Results]
    J --> O
    N --> O
```

**LLM Usage Pattern:**
```python
# Sequential generation with context
for section in outline:
    prompt = build_prompt(
        section=section,
        context=search_results,
        previous_sections=generated_content
    )
    content = await llm.generate(prompt)
    generated_content.append(content)
```

**Quality Metrics:**
- Coherence score
- Factual accuracy
- Citation coverage
- Readability index

**Duration:** ~30-120 seconds (varies by length)

### Stage 6: Quality Review âœ…

**Goal:** Ensure content meets quality standards.

**Review Checklist:**

| Category | Checks | Auto-Fix |
|----------|--------|----------|
| **Structure** | Heading hierarchy, section balance | âœ… |
| **Content** | Fact-checking, completeness | âš ï¸ Manual |
| **Style** | Tone consistency, grammar | âœ… |
| **Format** | Markdown syntax, citations | âœ… |
| **Logic** | Flow, transitions, coherence | âš ï¸ Manual |

**Review Process:**
1. **Automated Checks** - Run syntax and format validators
2. **LLM Review** - Quality assessment by reviewer agent
3. **Score Calculation** - Compute overall quality score
4. **Feedback Generation** - Create improvement suggestions
5. **Revision** (if needed) - Regenerate low-quality sections

**Threshold:**
- Score â‰¥ 0.85: Approve
- Score < 0.85: Request revision

**Duration:** ~5-10 seconds

### Stage 7: Format Conversion ğŸ”„

**Goal:** Transform Markdown to desired output formats.

**Conversion Pipeline:**

```mermaid
graph LR
    A[Markdown] --> B{Target Format}
    B -->|HTML| C[Markdown2 + Template]
    B -->|PDF| D[WeasyPrint]
    B -->|DOCX| E[python-docx]
    B -->|PPTX| F[python-pptx]
    
    C --> G[Styled HTML]
    D --> H[Professional PDF]
    E --> I[Formatted DOCX]
    F --> J[Designed PPTX]
```

**HTML Conversion:**
```python
import markdown2

html = markdown2.markdown(
    content,
    extras=[
        'tables',
        'fenced-code-blocks',
        'header-ids',
        'toc',
        'metadata'
    ]
)
```

**Template Application:**
```html
<!DOCTYPE html>
<html>
<head>
    <style>
        /* Custom styles for professional look */
    </style>
</head>
<body>
    {{ content }}
</body>
</html>
```

**Duration:** ~2-5 seconds per format

### Stage 8: Export Output ğŸ“¤

**Goal:** Save and deliver final output to user.

**Export Structure:**
```
storage/20251005_143022_AI_Industry_Trends/
â”œâ”€â”€ metadata.json
â”œâ”€â”€ intermediate/
â”‚   â”œâ”€â”€ 01_task_decomposition.json
â”‚   â”œâ”€â”€ 02_search_results.json
â”‚   â””â”€â”€ 03_content_outline.json
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ FINAL_REPORT.md
â”‚   â””â”€â”€ FINAL_REPORT.html
â””â”€â”€ exports/
    â”œâ”€â”€ report.pdf
    â””â”€â”€ report.docx
```

**Completion Summary:**
```
âœ… Generation Complete!

ğŸ“Š Statistics:
   - Duration: 2m 34s
   - Searches: 8 queries
   - Content: 5,432 words
   - Citations: 15 sources
   - Quality Score: 0.92

ğŸ“ Output Files:
   - Markdown: storage/.../FINAL_REPORT.md
   - HTML: storage/.../FINAL_REPORT.html
   - PDF: storage/.../exports/report.pdf

ğŸ”— Project ID: 20251005_143022
```

**Duration:** ~1-2 seconds

## Total Timeline

| Stage | Duration | Percentage |
|-------|----------|------------|
| Requirement Analysis | 1s | 1% |
| Task Decomposition | 3s | 2% |
| Parallel Search | 10s | 7% |
| Content Integration | 3s | 2% |
| Intelligent Generation | 90s | 60% |
| Quality Review | 8s | 5% |
| Format Conversion | 4s | 3% |
| Export Output | 1s | <1% |
| **Total** | **~120s** | **100%** |

::: tip Performance Tip
Most time is spent on content generation (LLM calls). Use faster models like GPT-3.5 for drafts, then iterate with GPT-4 for quality.
:::

## Iteration Workflow

When you request modifications:

```mermaid
sequenceDiagram
    participant U as User
    participant I as Iteration Agent
    participant S as Storage
    participant G as Generator
    participant E as Exporter

    U->>I: "Add more examples in chapter 3"
    I->>I: Analyze modification request
    I->>S: Create version backup
    I->>S: Load project context
    I->>G: Targeted regeneration
    G-->>I: Updated content
    I->>S: Save new version
    I->>E: Update exports
    E-->>U: Modification complete
```

**Key Differences from Initial Generation:**
- âœ… Preserves context
- âœ… Targets specific sections
- âœ… Maintains version history
- âœ… Faster execution (~30-60s)

## Monitoring & Observability

### Real-Time Progress

During execution, XunLong displays:

```
ğŸ‰ XunLong - Content Generation

ğŸ“‹ Task Analysis
âœ… Identified: Report Generation
âœ… Style: Business
âœ… Depth: Comprehensive

ğŸ” Searching Information
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 100% (8/8 queries)
âœ… Found 42 relevant sources

âœ¨ Generating Content
[â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘] 60% (3/5 sections)
â±ï¸  Elapsed: 1m 24s | Estimated: 48s remaining

```

### LangFuse Tracking

All operations are logged to LangFuse:

**Trace View:**
```
Trace: report_generation_20251005_143022
â”œâ”€ analyze_requirement (1.2s)
â”œâ”€ decompose_tasks (2.8s)
â”œâ”€ parallel_search (9.4s)
â”‚  â”œâ”€ search_query_1 (3.2s)
â”‚  â”œâ”€ search_query_2 (4.1s)
â”‚  â””â”€ search_query_3 (5.3s)
â”œâ”€ generate_content (89.3s)
â”‚  â”œâ”€ section_1 (15.2s, 1,234 tokens)
â”‚  â”œâ”€ section_2 (18.7s, 1,567 tokens)
â”‚  â”œâ”€ section_3 (22.1s, 1,892 tokens)
â”‚  â”œâ”€ section_4 (16.8s, 1,345 tokens)
â”‚  â””â”€ section_5 (14.2s, 1,123 tokens)
â”œâ”€ review_quality (7.9s)
â””â”€ export_formats (3.4s)
```

## Error Recovery

### Automatic Retry

Failed steps are automatically retried:

```python
@retry(max_attempts=3, backoff=exponential)
async def execute_search(query):
    try:
        return await search_engine.search(query)
    except NetworkError:
        # Will retry with backoff
        raise
```

### Checkpointing

Progress is checkpointed at each stage:

```
intermediate/
â”œâ”€â”€ 01_task_decomposition.json  âœ… Saved
â”œâ”€â”€ 02_search_results.json      âœ… Saved
â”œâ”€â”€ 03_content_outline.json     âœ… Saved
â””â”€â”€ 04_generated_sections.json  â¸ï¸  In Progress
```

If generation fails, you can resume:

```bash
python xunlong.py resume 20251005_143022
```

## Best Practices

### 1. Optimize Search Queries
- Be specific in your requests
- Include relevant keywords
- Specify time ranges if needed

### 2. Choose Appropriate Depth
- **Overview**: Quick 5-minute generation
- **Standard**: Balanced 10-minute generation
- **Comprehensive**: Detailed 20-minute generation

### 3. Monitor Token Usage
```bash
# Check token consumption
python xunlong.py stats 20251005_143022
```

### 4. Iterate Incrementally
- Start with standard depth
- Review output
- Request targeted improvements

## Next Steps

- Learn about [Report Generation](/guide/features/report)
- Explore [Fiction Writing](/guide/features/fiction)
- Try [PPT Creation](/guide/features/ppt)
- Understand [Iteration](/guide/features/iteration)
