"""
å›¾ç‰‡åŠŸèƒ½æµ‹è¯•ç¤ºä¾‹

æµ‹è¯•å†…å®¹:
1. å›¾ç‰‡æœç´¢ (Unsplash/Pexels)
2. å›¾ç‰‡ä¸‹è½½å’Œæœ¬åœ°å­˜å‚¨
3. å›¾ç‰‡æ’å…¥åˆ°Markdownå†…å®¹
4. å®Œæ•´çš„æŠ¥å‘Šç”Ÿæˆæµç¨‹ï¼ˆå¸¦é…å›¾ï¼‰
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from loguru import logger
from src.tools.image_searcher import ImageSearcher
from src.tools.image_downloader import ImageDownloader
from src.utils.image_processor import ImageProcessor


async def test_image_search():
    """æµ‹è¯•å›¾ç‰‡æœç´¢åŠŸèƒ½"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•1: å›¾ç‰‡æœç´¢åŠŸèƒ½")
    logger.info("=" * 60)

    searcher = ImageSearcher()

    if not searcher.is_available():
        logger.warning("æœªé…ç½®å›¾ç‰‡APIå¯†é’¥ï¼Œè·³è¿‡æµ‹è¯•")
        logger.info("è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½® UNSPLASH_ACCESS_KEY æˆ– PEXELS_API_KEY")
        return None

    logger.info(f"å¯ç”¨çš„å›¾ç‰‡æº: {searcher.get_available_sources()}")

    # æœç´¢æµ‹è¯•
    query = "artificial intelligence technology"
    logger.info(f"æœç´¢å…³é”®è¯: {query}")

    images = await searcher.search_images(query, count=3)

    if images:
        logger.success(f"âœ“ æˆåŠŸæœç´¢åˆ° {len(images)} å¼ å›¾ç‰‡")
        for i, img in enumerate(images, 1):
            logger.info(
                f"  {i}. {img.get('alt', 'N/A')[:50]} "
                f"({img.get('width')}x{img.get('height')}) "
                f"- {img.get('source', 'unknown')}"
            )
        return images
    else:
        logger.error("âœ— å›¾ç‰‡æœç´¢å¤±è´¥")
        return None


async def test_image_download(images):
    """æµ‹è¯•å›¾ç‰‡ä¸‹è½½åŠŸèƒ½"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•2: å›¾ç‰‡ä¸‹è½½åŠŸèƒ½")
    logger.info("=" * 60)

    if not images:
        logger.warning("æ²¡æœ‰å›¾ç‰‡å¯ä¾›ä¸‹è½½ï¼Œè·³è¿‡æµ‹è¯•")
        return None

    downloader = ImageDownloader(
        storage_dir=Path("storage/test_images"),
        max_image_size=1024,
        quality=80
    )

    logger.info(f"å¼€å§‹ä¸‹è½½ {len(images)} å¼ å›¾ç‰‡...")
    downloaded_images = await downloader.download_images(images[:2], optimize=True)

    if downloaded_images:
        logger.success(f"âœ“ æˆåŠŸä¸‹è½½ {len(downloaded_images)} å¼ å›¾ç‰‡")
        for img in downloaded_images:
            if img.get('local_path'):
                logger.info(f"  - {img.get('local_path')} ({img.get('size', 0)} bytes)")
        return downloaded_images
    else:
        logger.error("âœ— å›¾ç‰‡ä¸‹è½½å¤±è´¥")
        return None


def test_image_insertion(images):
    """æµ‹è¯•å›¾ç‰‡æ’å…¥åŠŸèƒ½"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•3: å›¾ç‰‡æ’å…¥åˆ°Markdown")
    logger.info("=" * 60)

    if not images:
        logger.warning("æ²¡æœ‰å›¾ç‰‡å¯ä¾›æ’å…¥ï¼Œè·³è¿‡æµ‹è¯•")
        return

    # åˆ›å»ºç¤ºä¾‹å†…å®¹
    sample_content = """
# äººå·¥æ™ºèƒ½æŠ€æœ¯æ¦‚è¿°

äººå·¥æ™ºèƒ½(Artificial Intelligence, AI)æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œè‡´åŠ›äºç ”ç©¶ã€å¼€å‘ç”¨äºæ¨¡æ‹Ÿã€å»¶ä¼¸å’Œæ‰©å±•äººçš„æ™ºèƒ½çš„ç†è®ºã€æ–¹æ³•ã€æŠ€æœ¯åŠåº”ç”¨ç³»ç»Ÿã€‚

## å‘å±•å†å²

äººå·¥æ™ºèƒ½çš„æ¦‚å¿µæœ€æ—©ç”±John McCarthyåœ¨1956å¹´æå‡ºã€‚ç»è¿‡å‡ åå¹´çš„å‘å±•ï¼ŒAIæŠ€æœ¯å·²ç»æ¸—é€åˆ°æˆ‘ä»¬ç”Ÿæ´»çš„æ–¹æ–¹é¢é¢ã€‚

## æ ¸å¿ƒæŠ€æœ¯

ç°ä»£äººå·¥æ™ºèƒ½ä¸»è¦åŒ…æ‹¬æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰å¤šä¸ªæŠ€æœ¯é¢†åŸŸã€‚

## åº”ç”¨åœºæ™¯

AIæŠ€æœ¯å·²å¹¿æ³›åº”ç”¨äºæ™ºèƒ½åŠ©æ‰‹ã€è‡ªåŠ¨é©¾é©¶ã€åŒ»ç–—è¯Šæ–­ã€é‡‘èé£æ§ç­‰ä¼—å¤šé¢†åŸŸã€‚
"""

    # æµ‹è¯•ä¸åŒæ’å…¥æ¨¡å¼
    modes = ["smart", "top", "bottom", "distribute"]

    for mode in modes:
        logger.info(f"\næµ‹è¯•æ’å…¥æ¨¡å¼: {mode}")
        result = ImageProcessor.insert_images_to_content(
            sample_content, images, mode=mode
        )

        # ä¿å­˜ç»“æœ
        output_file = Path(f"storage/test_images/result_{mode}.md")
        output_file.parent.mkdir(parents=True, exist_ok=True)
        output_file.write_text(result, encoding='utf-8')

        logger.success(f"âœ“ æ¨¡å¼ '{mode}' æµ‹è¯•å®Œæˆï¼Œç»“æœä¿å­˜åˆ°: {output_file}")
        logger.info(f"  å†…å®¹é•¿åº¦: {len(result)} å­—ç¬¦")


async def test_batch_search():
    """æµ‹è¯•æ‰¹é‡æœç´¢åŠŸèƒ½"""
    logger.info("\n" + "=" * 60)
    logger.info("æµ‹è¯•4: æ‰¹é‡ç« èŠ‚å›¾ç‰‡æœç´¢")
    logger.info("=" * 60)

    searcher = ImageSearcher()

    if not searcher.is_available():
        logger.warning("æœªé…ç½®å›¾ç‰‡APIå¯†é’¥ï¼Œè·³è¿‡æµ‹è¯•")
        return

    # æ¨¡æ‹Ÿç« èŠ‚
    sections = [
        {"id": "section_1", "title": "Machine Learning Basics"},
        {"id": "section_2", "title": "Deep Learning Networks"},
        {"id": "section_3", "title": "Natural Language Processing"},
    ]

    logger.info(f"ä¸º {len(sections)} ä¸ªç« èŠ‚æœç´¢é…å›¾...")
    section_images = await searcher.search_images_for_sections(sections, images_per_section=2)

    for section in sections:
        section_id = section['id']
        images = section_images.get(section_id, [])
        logger.info(f"  {section['title']}: {len(images)} å¼ å›¾ç‰‡")

    logger.success("âœ“ æ‰¹é‡æœç´¢æµ‹è¯•å®Œæˆ")


async def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    logger.info("â•”" + "â•" * 58 + "â•—")
    logger.info("â•‘" + " " * 15 + "å›¾ç‰‡åŠŸèƒ½æµ‹è¯•å¥—ä»¶" + " " * 25 + "â•‘")
    logger.info("â•š" + "â•" * 58 + "â•\n")

    try:
        # æµ‹è¯•1: å›¾ç‰‡æœç´¢
        images = await test_image_search()

        # æµ‹è¯•2: å›¾ç‰‡ä¸‹è½½
        if images:
            downloaded_images = await test_image_download(images)

            # æµ‹è¯•3: å›¾ç‰‡æ’å…¥
            if downloaded_images:
                test_image_insertion(downloaded_images)

        # æµ‹è¯•4: æ‰¹é‡æœç´¢
        await test_batch_search()

        logger.info("\n" + "=" * 60)
        logger.success("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        logger.info("=" * 60)

        logger.info("\nğŸ“ æµ‹è¯•ç»“æœæ€»ç»“:")
        logger.info("  - å›¾ç‰‡æœç´¢: å·²æµ‹è¯•")
        logger.info("  - å›¾ç‰‡ä¸‹è½½: å·²æµ‹è¯•")
        logger.info("  - å›¾ç‰‡æ’å…¥: å·²æµ‹è¯•")
        logger.info("  - æ‰¹é‡æœç´¢: å·²æµ‹è¯•")

        logger.info("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        logger.info("  1. æŸ¥çœ‹ storage/test_images/ ç›®å½•ä¸­çš„æµ‹è¯•ç»“æœ")
        logger.info("  2. åœ¨å®é™…æŠ¥å‘Šç”Ÿæˆä¸­å¯ç”¨å›¾ç‰‡åŠŸèƒ½")
        logger.info("  3. é…ç½® .env æ–‡ä»¶ä¸­çš„å›¾ç‰‡APIå¯†é’¥")

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
